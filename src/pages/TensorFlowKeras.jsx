import React from 'react';
import Slidebar from '../components/Slidebar';
import { Prism as SyntaxHighlighter } from 'react-syntax-highlighter';
import { atomDark } from 'react-syntax-highlighter/dist/esm/styles/prism';

const codeTensorFlow = `import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.datasets import imdb
from tensorflow.keras.preprocessing.sequence import pad_sequences

# --- 1. Cargar y Preprocesar los Datos ---

# Cargamos el dataset. Nos quedamos con las 10,000 palabras m√°s frecuentes.
(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)

# Las rese√±as son listas de n√∫meros (√≠ndices de palabras) y tienen longitudes diferentes.
# Las redes neuronales necesitan entradas de tama√±o uniforme.
# Usamos "pad_sequences" para que todas las rese√±as tengan una longitud de 256 palabras.
# Si una rese√±a es m√°s corta, se rellena con ceros. Si es m√°s larga, se trunca.
train_data = pad_sequences(train_data, value=0, padding='post', maxlen=256)
test_data = pad_sequences(test_data, value=0, padding='post', maxlen=256)

# --- 2. Construir la Red Neuronal ---

# Usamos el modelo "Sequential", que es una pila lineal de capas.
model = keras.Sequential([
    # Capa de Embedding: Esta capa es especial para texto. Convierte los √≠ndices de palabras
    # en vectores densos de un tama√±o fijo (16 en este caso). Aprende asociaciones de palabras.
    keras.layers.Embedding(10000, 16),
    
    # Capa GlobalAveragePooling1D: Promedia los vectores de palabras para cada rese√±a.
    # Esto nos da una salida de tama√±o fijo para cada ejemplo, independientemente de la longitud.
    keras.layers.GlobalAveragePooling1D(),
    
    # Capa Densa (Oculta): Nuestra primera capa oculta con 16 neuronas.
    # Usa la activaci√≥n ReLU para introducir no-linealidad.
    keras.layers.Dense(16, activation='relu'),
    
    # Capa Densa (Salida): La capa final. Tiene 1 neurona porque es una clasificaci√≥n binaria.
    # Usa la activaci√≥n Sigmoide para dar una salida entre 0 y 1 (probabilidad).
    keras.layers.Dense(1, activation='sigmoid')
])

# Mostramos un resumen de la arquitectura de nuestro modelo.
model.summary()

# --- 3. Compilar el Modelo ---

# Antes de entrenar, debemos configurar el proceso de aprendizaje.
model.compile(optimizer='adam',              # Algoritmo para minimizar la p√©rdida (Adam es muy popular).
              loss='binary_crossentropy', # Funci√≥n de p√©rdida para clasificaci√≥n binaria.
              metrics=['accuracy'])         # M√©trica para monitorear el rendimiento (exactitud).

# --- 4. Entrenar el Modelo ---

# Separamos una parte de los datos de entrenamiento para validaci√≥n.
# La validaci√≥n nos ayuda a ver qu√© tal generaliza el modelo con datos que no ha visto.
x_val = train_data[:10000]
partial_x_train = train_data[10000:]
y_val = train_labels[:10000]
partial_y_train = train_labels[10000:]

# Entrenamos el modelo.
# epochs: N√∫mero de veces que el modelo ver√° todo el conjunto de datos de entrenamiento.
# batch_size: N√∫mero de ejemplos que se usan en una sola pasada para actualizar los pesos.
history = model.fit(partial_x_train,
                    partial_y_train,
                    epochs=40,
                    batch_size=512,
                    validation_data=(x_val, y_val),
                    verbose=1)

# --- 5. Evaluar el Modelo ---

# Una vez entrenado, evaluamos su rendimiento en el conjunto de prueba (datos nunca vistos).
results = model.evaluate(test_data, test_labels, verbose=2)
print("\\nP√©rdida en prueba:", results[0])
print("Exactitud en prueba:", results[1])

# --- 6. Hacer Predicciones ---

# Podemos usar el modelo entrenado para predecir en nuevos datos.
predictions = model.predict(test_data)
print("\\nPredicci√≥n para la primera rese√±a de prueba:", predictions[0])
print("Etiqueta real:", test_labels[0])
# Si la predicci√≥n es > 0.5, es positiva. Si es < 0.5, es negativa.`;

const codeSimpleNN = `# Red Neuronal Simple para Clasificaci√≥n de Flores Iris
import tensorflow as tf
from tensorflow import keras
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# --- 1. Cargar y Preparar los Datos ---
iris = load_iris()
X, y = iris.data, iris.target

# Solo usamos 2 clases para simplificar (clasificaci√≥n binaria)
X = X[y != 2]
y = y[y != 2]

# Dividir datos
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Escalar los datos
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# --- 2. Construir la Red Neuronal ---
model = keras.Sequential([
    keras.layers.Dense(8, activation='relu', input_shape=(4,)),  # Capa oculta
    keras.layers.Dense(1, activation='sigmoid')                  # Capa de salida
])

# --- 3. Compilar y Entrenar ---
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, verbose=0)

# --- 4. Evaluar ---
test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test, verbose=0)
print(f"Exactitud en prueba: {test_accuracy:.3f}")`;

const codeVisualization = `import matplotlib.pyplot as plt
import numpy as np

# Visualizar el entrenamiento
plt.figure(figsize=(12, 4))

# Gr√°fico de p√©rdida
plt.subplot(1, 2, 1)
plt.plot(history.history['loss'], label='P√©rdida de Entrenamiento')
plt.plot(history.history['val_loss'], label='P√©rdida de Validaci√≥n')
plt.title('P√©rdida durante el Entrenamiento')
plt.xlabel('√âpoca')
plt.ylabel('P√©rdida')
plt.legend()

# Gr√°fico de exactitud
plt.subplot(1, 2, 2)
plt.plot(history.history['accuracy'], label='Exactitud de Entrenamiento')
plt.plot(history.history['val_accuracy'], label='Exactitud de Validaci√≥n')
plt.title('Exactitud durante el Entrenamiento')
plt.xlabel('√âpoca')
plt.ylabel('Exactitud')
plt.legend()

plt.tight_layout()
plt.show()`;

const sectionCard = {
  background: 'var(--bg-secondary, #fff)',
  borderRadius: 16,
  boxShadow: '0 2px 12px rgba(0,0,0,0.07)',
  padding: 32,
  marginBottom: 32,
  border: '1px solid #e5e7eb',
  maxWidth: 1100,
  width: '100%',
  marginLeft: 'auto',
  marginRight: 'auto',
};

const accentTitle = {
  color: '#a259f7',
  display: 'flex',
  alignItems: 'center',
  gap: 10,
  fontWeight: 700,
  fontSize: 24,
  marginBottom: 10,
};

const subtitle = {
  color: '#16a34a',
  fontWeight: 600,
  fontSize: 18,
  margin: '18px 0 8px 0',
  display: 'flex',
  alignItems: 'center',
  gap: 8,
};

const TensorFlowKeras = ({ isDarkTheme, onToggleTheme }) => (
  <div className="admin-panel">
    <Slidebar open={true} onClose={() => {}} isDarkTheme={isDarkTheme} alwaysVisible={true} />
    <div className="main-content" style={{ marginLeft: 260, maxWidth: '100%', background: 'transparent', minHeight: '100vh', paddingBottom: 60 }}>
      <div style={sectionCard}>
        <div style={accentTitle}>
          <span role="img" aria-label="robot">ü§ñ</span> TensorFlow & Keras
        </div>
        <div style={{ fontSize: 17, lineHeight: 1.7 }}>
          <b>Introducci√≥n: Construcci√≥n de una Red Neuronal Simple</b><br/>
          Ahora, vamos a la pr√°ctica. Keras es una API de alto nivel dentro de TensorFlow que hace que construir 
          redes neuronales sea muy intuitivo. Vamos a construir una red neuronal que clasifique rese√±as de pel√≠culas 
          como "positivas" o "negativas" utilizando el famoso conjunto de datos IMDB.<br/><br/>

          <div style={subtitle}>üì¶ Instalaci√≥n</div>
          Si no tienes TensorFlow instalado, abre una terminal o l√≠nea de comandos y ejecuta:<br/><br/>

          <div style={{ 
            background: '#2d3748', 
            color: '#e2e8f0', 
            padding: '15px', 
            borderRadius: '8px', 
            fontFamily: 'monospace',
            marginBottom: '20px'
          }}>
            pip install tensorflow
          </div>

          <div style={subtitle}>üé¨ Problema: Clasificaci√≥n de Rese√±as de Pel√≠culas</div>
          Vamos a construir una red neuronal que clasifique rese√±as de pel√≠culas como "positivas" o "negativas" 
          utilizando el dataset IMDB. Este es un problema de clasificaci√≥n binaria perfecto para empezar.<br/><br/>

          <div style={subtitle}>üßë‚Äçüíª C√≥digo Completo con Explicaciones</div>
          <SyntaxHighlighter language="python" style={atomDark} customStyle={{ borderRadius: 10, fontSize: 14, margin: '18px 0' }}>{codeTensorFlow}</SyntaxHighlighter>

          <div style={subtitle}>üîç Explicaci√≥n Paso a Paso</div>
          
          <div style={{ 
            background: '#f8f9fa', 
            padding: '20px', 
            borderRadius: '8px', 
            border: '1px solid #e9ecef',
            marginBottom: '20px'
          }}>
            <h4 style={{ color: '#495057', marginBottom: '15px' }}>1. Carga y Preprocesamiento de Datos</h4>
            <ul style={{ margin: 0, paddingLeft: '20px' }}>
              <li><b>Dataset IMDB:</b> 50,000 rese√±as de pel√≠culas (25,000 para entrenamiento, 25,000 para prueba)</li>
              <li><b>Vocabulario:</b> Limitado a las 10,000 palabras m√°s frecuentes</li>
              <li><b>Padding:</b> Todas las rese√±as se ajustan a 256 palabras para uniformidad</li>
            </ul>
          </div>

          <div style={{ 
            background: '#f8f9fa', 
            padding: '20px', 
            borderRadius: '8px', 
            border: '1px solid #e9ecef',
            marginBottom: '20px'
          }}>
            <h4 style={{ color: '#495057', marginBottom: '15px' }}>2. Arquitectura de la Red</h4>
            <ul style={{ margin: 0, paddingLeft: '20px' }}>
              <li><b>Embedding:</b> Convierte palabras en vectores densos de 16 dimensiones</li>
              <li><b>GlobalAveragePooling1D:</b> Promedia los vectores de palabras de cada rese√±a</li>
              <li><b>Dense(16, relu):</b> Capa oculta con 16 neuronas y activaci√≥n ReLU</li>
              <li><b>Dense(1, sigmoid):</b> Capa de salida con 1 neurona y activaci√≥n sigmoide</li>
            </ul>
          </div>

          <div style={{ 
            background: '#f8f9fa', 
            padding: '20px', 
            borderRadius: '8px', 
            border: '1px solid #e9ecef',
            marginBottom: '20px'
          }}>
            <h4 style={{ color: '#495057', marginBottom: '15px' }}>3. Compilaci√≥n del Modelo</h4>
            <ul style={{ margin: 0, paddingLeft: '20px' }}>
              <li><b>Optimizer:</b> Adam (algoritmo de optimizaci√≥n adaptativo)</li>
              <li><b>Loss:</b> binary_crossentropy (funci√≥n de p√©rdida para clasificaci√≥n binaria)</li>
              <li><b>Metrics:</b> accuracy (m√©trica para monitorear el rendimiento)</li>
            </ul>
          </div>

          <div style={subtitle}>üéØ Ejemplo M√°s Simple: Clasificaci√≥n de Flores</div>
          Para entender mejor los conceptos, aqu√≠ tienes un ejemplo m√°s simple usando el dataset Iris:<br/><br/>

          <SyntaxHighlighter language="python" style={atomDark} customStyle={{ borderRadius: 10, fontSize: 14, margin: '18px 0' }}>{codeSimpleNN}</SyntaxHighlighter>

          <div style={subtitle}>üìä Visualizaci√≥n del Entrenamiento</div>
          Es importante monitorear el entrenamiento para detectar overfitting:<br/><br/>

          <SyntaxHighlighter language="python" style={atomDark} customStyle={{ borderRadius: 10, fontSize: 14, margin: '18px 0' }}>{codeVisualization}</SyntaxHighlighter>

          <div style={subtitle}>üîß Conceptos Clave de Keras</div>
          
          <div style={{ display: 'grid', gridTemplateColumns: '1fr 1fr', gap: '20px', marginBottom: '20px' }}>
            <div style={{ background: '#e8f5e8', padding: '15px', borderRadius: '8px' }}>
              <h4 style={{ color: '#2d5a2d', marginBottom: '10px' }}>üèóÔ∏è Modelo Sequential</h4>
              <ul style={{ margin: 0, paddingLeft: '20px' }}>
                <li>Pila lineal de capas</li>
                <li>F√°cil de construir y entender</li>
                <li>Ideal para la mayor√≠a de problemas</li>
                <li>No permite conexiones complejas</li>
              </ul>
            </div>
            <div style={{ background: '#fff3cd', padding: '15px', borderRadius: '8px' }}>
              <h4 style={{ color: '#856404', marginBottom: '10px' }}>‚öôÔ∏è Compilaci√≥n</h4>
              <ul style={{ margin: 0, paddingLeft: '20px' }}>
                <li>Define el optimizador</li>
                <li>Especifica la funci√≥n de p√©rdida</li>
                <li>Configura las m√©tricas</li>
                <li>Prepara el modelo para entrenamiento</li>
              </ul>
            </div>
          </div>

          <div style={subtitle}>üìà Hiperpar√°metros Importantes</div>
          
          <div style={{ 
            background: '#f8f9fa', 
            padding: '20px', 
            borderRadius: '8px', 
            border: '1px solid #e9ecef',
            marginBottom: '20px'
          }}>
            <div style={{ display: 'grid', gridTemplateColumns: '1fr 1fr', gap: '20px' }}>
              <div>
                <h4 style={{ color: '#495057', marginBottom: '10px' }}>üéØ Epochs</h4>
                <p style={{ margin: 0, lineHeight: '1.6' }}>
                  N√∫mero de veces que el modelo ve todo el dataset. Demasiados pueden causar overfitting.
                </p>
              </div>
              <div>
                <h4 style={{ color: '#495057', marginBottom: '10px' }}>üì¶ Batch Size</h4>
                <p style={{ margin: 0, lineHeight: '1.6' }}>
                  N√∫mero de ejemplos procesados antes de actualizar los pesos. Afecta la velocidad y estabilidad.
                </p>
              </div>
              <div>
                <h4 style={{ color: '#495057', marginBottom: '10px' }}>üîç Validation Split</h4>
                <p style={{ margin: 0, lineHeight: '1.6' }}>
                  Porcentaje de datos de entrenamiento usado para validaci√≥n. Ayuda a detectar overfitting.
                </p>
              </div>
              <div>
                <h4 style={{ color: '#495057', marginBottom: '10px' }}>‚ö° Learning Rate</h4>
                <p style={{ margin: 0, lineHeight: '1.6' }}>
                  Tama√±o de los pasos en la optimizaci√≥n. Demasiado alto puede causar inestabilidad.
                </p>
              </div>
            </div>
          </div>

          <div style={subtitle}>‚ö†Ô∏è Problemas Comunes y Soluciones</div>
          
          <div style={{ display: 'grid', gridTemplateColumns: '1fr 1fr', gap: '20px', marginBottom: '20px' }}>
            <div style={{ background: '#ffe6e6', padding: '15px', borderRadius: '8px' }}>
              <h4 style={{ color: '#dc2626', marginBottom: '10px' }}>‚ùå Overfitting</h4>
              <ul style={{ margin: 0, paddingLeft: '20px' }}>
                <li>El modelo memoriza los datos de entrenamiento</li>
                <li>Buen rendimiento en entrenamiento, malo en prueba</li>
                <li><strong>Soluci√≥n:</strong> Dropout, regularizaci√≥n, m√°s datos</li>
              </ul>
            </div>
            <div style={{ background: '#ffe6e6', padding: '15px', borderRadius: '8px' }}>
              <h4 style={{ color: '#dc2626', marginBottom: '10px' }}>‚ùå Underfitting</h4>
              <ul style={{ margin: 0, paddingLeft: '20px' }}>
                <li>El modelo es demasiado simple</li>
                <li>Mal rendimiento en entrenamiento y prueba</li>
                <li><strong>Soluci√≥n:</strong> M√°s capas, m√°s neuronas, m√°s √©pocas</li>
              </ul>
            </div>
          </div>

          <div style={{ 
            background: 'linear-gradient(135deg, #667eea 0%, #764ba2 100%)', 
            color: 'white', 
            padding: '20px', 
            borderRadius: '12px',
            marginTop: '30px'
          }}>
            <h3 style={{ marginBottom: '15px' }}>üöÄ Pr√≥ximos Pasos</h3>
            <ul style={{ margin: 0, paddingLeft: '20px', lineHeight: '1.6' }}>
              <li>Experimenta con diferentes arquitecturas de red</li>
              <li>Prueba diferentes optimizadores (SGD, RMSprop, Adam)</li>
              <li>A√±ade regularizaci√≥n (Dropout, L1/L2)</li>
              <li>Implementa early stopping para prevenir overfitting</li>
              <li>Explora t√©cnicas de data augmentation</li>
              <li>Considera usar callbacks para monitoreo avanzado</li>
            </ul>
          </div>
        </div>
      </div>
    </div>
    <button
      className="theme-toggle-btn"
      onClick={onToggleTheme}
      title={isDarkTheme ? "Cambiar a tema claro" : "Cambiar a tema oscuro"}
    >
      {isDarkTheme ? '‚òÄÔ∏è' : 'üåô'}
    </button>
  </div>
);

export default TensorFlowKeras; 